{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b16b616-4cee-46f0-bb21-a360d3328615",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to scraped_data_with_all_replies.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "def scrape_replies(driver, topic_url):\n",
    "    driver.get(topic_url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    all_replies = []\n",
    "\n",
    "    while True:\n",
    "        reply_elements = driver.find_elements(By.CSS_SELECTOR, 'div._36ZEkSvpdj_igmog0nluzh')\n",
    "        for reply_element in reply_elements:\n",
    "            reply_text = reply_element.text.replace(\"\\n\", \" \").strip()\n",
    "            all_replies.append(reply_text)\n",
    "\n",
    "        next_page_buttons = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/page/']\")\n",
    "        next_page_found = False\n",
    "        for button in next_page_buttons:\n",
    "            if button.text == \"下一頁\":\n",
    "                next_url = button.get_attribute('href')\n",
    "                driver.get(next_url)\n",
    "                time.sleep(5)  # Wait for the next page to load\n",
    "                next_page_found = True\n",
    "                break\n",
    "\n",
    "        if not next_page_found:\n",
    "            break\n",
    "\n",
    "    return \" | \".join(all_replies)\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chromedriver_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\Miki\\\\5508\\\\Project\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "service = Service(executable_path=chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "url = 'https://lihkg.com/search?q=%E9%A8%99%E6%A1%88&sort=desc_create_time&type=thread'\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "data = []\n",
    "topics = driver.find_elements(By.CLASS_NAME, 'wQ4Ran7ySbKd8PdMeHZZR')\n",
    "\n",
    "for topic in topics:\n",
    "    title = topic.find_element(By.CSS_SELECTOR, 'span._20jopXBFHNQ9FUbcGHLcHH').text.strip()\n",
    "    username = topic.find_element(By.CSS_SELECTOR, 'span.CxY4XDSSItTeLVg0cKCN0').text.strip()\n",
    "    topic_url_element = topic.find_element(By.CSS_SELECTOR, 'a._2A_7bGY9QAXcGu1neEYDJB')\n",
    "    topic_url = topic_url_element.get_attribute('href')\n",
    "\n",
    "    driver.execute_script(\"window.open('{}');\".format(topic_url))\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')))\n",
    "\n",
    "    main_content_element = driver.find_element(By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')\n",
    "    main_content = main_content_element.text if main_content_element else \"Content not found\"\n",
    "\n",
    "    likes_element = driver.find_element(By.CSS_SELECTOR, 'label._1yxPOd27pAzF9olhItRDej')\n",
    "    likes = likes_element.text if likes_element else \"Likes not found\"\n",
    "\n",
    "    dislikes_element = driver.find_element(By.CSS_SELECTOR, 'label._2iRKJuMIV77zdwLRreUgLK')\n",
    "    dislikes = dislikes_element.text if dislikes_element else \"Dislikes not found\"\n",
    "\n",
    "    replies = scrape_replies(driver, topic_url)\n",
    "\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "    data.append([title, username, main_content, likes, dislikes, topic_url, replies])\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "csv_file_name = \"scraped_data_with_all_replies.csv\"\n",
    "\n",
    "with open(csv_file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Username\", \"Main Content\", \"Likes\", \"Dislikes\", \"URL\", \"All Replies\"])\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Data successfully written to {csv_file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40dda465-56f3-4307-9524-729403c009e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scam below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a3956e3-dd04-42c0-81f8-86e10b8a7535",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to scam.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "def scrape_replies(driver, topic_url):\n",
    "    driver.get(topic_url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    all_replies = []\n",
    "\n",
    "    while True:\n",
    "        reply_elements = driver.find_elements(By.CSS_SELECTOR, 'div._36ZEkSvpdj_igmog0nluzh')\n",
    "        for reply_element in reply_elements:\n",
    "            reply_text = reply_element.text.replace(\"\\n\", \" \").strip()\n",
    "            all_replies.append(reply_text)\n",
    "\n",
    "        next_page_buttons = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/page/']\")\n",
    "        next_page_found = False\n",
    "        for button in next_page_buttons:\n",
    "            if button.text == \"下一頁\":\n",
    "                next_url = button.get_attribute('href')\n",
    "                driver.get(next_url)\n",
    "                time.sleep(5)  # Wait for the next page to load\n",
    "                next_page_found = True\n",
    "                break\n",
    "\n",
    "        if not next_page_found:\n",
    "            break\n",
    "\n",
    "    return \" | \".join(all_replies)\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chromedriver_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\Miki\\\\5508\\\\Project\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "service = Service(executable_path=chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "url = 'https://lihkg.com/search?q=Scam&sort=desc_create_time&type=thread'\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "data = []\n",
    "topics = driver.find_elements(By.CLASS_NAME, 'wQ4Ran7ySbKd8PdMeHZZR')\n",
    "\n",
    "for topic in topics:\n",
    "    title = topic.find_element(By.CSS_SELECTOR, 'span._20jopXBFHNQ9FUbcGHLcHH').text.strip()\n",
    "    username = topic.find_element(By.CSS_SELECTOR, 'span.CxY4XDSSItTeLVg0cKCN0').text.strip()\n",
    "    topic_url_element = topic.find_element(By.CSS_SELECTOR, 'a._2A_7bGY9QAXcGu1neEYDJB')\n",
    "    topic_url = topic_url_element.get_attribute('href')\n",
    "\n",
    "    driver.execute_script(\"window.open('{}');\".format(topic_url))\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')))\n",
    "\n",
    "    main_content_element = driver.find_element(By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')\n",
    "    main_content = main_content_element.text if main_content_element else \"Content not found\"\n",
    "\n",
    "    likes_element = driver.find_element(By.CSS_SELECTOR, 'label._1yxPOd27pAzF9olhItRDej')\n",
    "    likes = likes_element.text if likes_element else \"Likes not found\"\n",
    "\n",
    "    dislikes_element = driver.find_element(By.CSS_SELECTOR, 'label._2iRKJuMIV77zdwLRreUgLK')\n",
    "    dislikes = dislikes_element.text if dislikes_element else \"Dislikes not found\"\n",
    "\n",
    "    replies = scrape_replies(driver, topic_url)\n",
    "\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "    data.append([title, username, main_content, likes, dislikes, topic_url, replies])\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "csv_file_name = \"scam.csv\"\n",
    "\n",
    "with open(csv_file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Username\", \"Main Content\", \"Likes\", \"Dislikes\", \"URL\", \"All Replies\"])\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Data successfully written to {csv_file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7710bde8-46a2-4df6-ae47-7400f1a3268b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "831d7350-5c23-4369-a1ff-e559609889b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to 火raud.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "def scrape_replies(driver, topic_url):\n",
    "    driver.get(topic_url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    all_replies = []\n",
    "\n",
    "    while True:\n",
    "        reply_elements = driver.find_elements(By.CSS_SELECTOR, 'div._36ZEkSvpdj_igmog0nluzh')\n",
    "        for reply_element in reply_elements:\n",
    "            reply_text = reply_element.text.replace(\"\\n\", \" \").strip()\n",
    "            all_replies.append(reply_text)\n",
    "\n",
    "        next_page_buttons = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/page/']\")\n",
    "        next_page_found = False\n",
    "        for button in next_page_buttons:\n",
    "            if button.text == \"下一頁\":\n",
    "                next_url = button.get_attribute('href')\n",
    "                driver.get(next_url)\n",
    "                time.sleep(5)  # Wait for the next page to load\n",
    "                next_page_found = True\n",
    "                break\n",
    "\n",
    "        if not next_page_found:\n",
    "            break\n",
    "\n",
    "    return \" | \".join(all_replies)\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chromedriver_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\Miki\\\\5508\\\\Project\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "service = Service(executable_path=chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "url = 'https://lihkg.com/search?q=Fraud&sort=desc_create_time&type=thread'\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "data = []\n",
    "topics = driver.find_elements(By.CLASS_NAME, 'wQ4Ran7ySbKd8PdMeHZZR')\n",
    "\n",
    "for topic in topics:\n",
    "    title = topic.find_element(By.CSS_SELECTOR, 'span._20jopXBFHNQ9FUbcGHLcHH').text.strip()\n",
    "    username = topic.find_element(By.CSS_SELECTOR, 'span.CxY4XDSSItTeLVg0cKCN0').text.strip()\n",
    "    topic_url_element = topic.find_element(By.CSS_SELECTOR, 'a._2A_7bGY9QAXcGu1neEYDJB')\n",
    "    topic_url = topic_url_element.get_attribute('href')\n",
    "\n",
    "    driver.execute_script(\"window.open('{}');\".format(topic_url))\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')))\n",
    "\n",
    "    main_content_element = driver.find_element(By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')\n",
    "    main_content = main_content_element.text if main_content_element else \"Content not found\"\n",
    "\n",
    "    likes_element = driver.find_element(By.CSS_SELECTOR, 'label._1yxPOd27pAzF9olhItRDej')\n",
    "    likes = likes_element.text if likes_element else \"Likes not found\"\n",
    "\n",
    "    dislikes_element = driver.find_element(By.CSS_SELECTOR, 'label._2iRKJuMIV77zdwLRreUgLK')\n",
    "    dislikes = dislikes_element.text if dislikes_element else \"Dislikes not found\"\n",
    "\n",
    "    replies = scrape_replies(driver, topic_url)\n",
    "\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "    data.append([title, username, main_content, likes, dislikes, topic_url, replies])\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "csv_file_name = \"火raud.csv\"\n",
    "\n",
    "with open(csv_file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Username\", \"Main Content\", \"Likes\", \"Dislikes\", \"URL\", \"All Replies\"])\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Data successfully written to {csv_file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6860424f-940d-4546-a0c9-0cf7fe3455e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#欺騙"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b24d6e4c-5390-4b23-987e-4ecfb512b711",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to 欺騙.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "def scrape_replies(driver, topic_url):\n",
    "    driver.get(topic_url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    all_replies = []\n",
    "\n",
    "    while True:\n",
    "        reply_elements = driver.find_elements(By.CSS_SELECTOR, 'div._36ZEkSvpdj_igmog0nluzh')\n",
    "        for reply_element in reply_elements:\n",
    "            reply_text = reply_element.text.replace(\"\\n\", \" \").strip()\n",
    "            all_replies.append(reply_text)\n",
    "\n",
    "        next_page_buttons = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/page/']\")\n",
    "        next_page_found = False\n",
    "        for button in next_page_buttons:\n",
    "            if button.text == \"下一頁\":\n",
    "                next_url = button.get_attribute('href')\n",
    "                driver.get(next_url)\n",
    "                time.sleep(5)  # Wait for the next page to load\n",
    "                next_page_found = True\n",
    "                break\n",
    "\n",
    "        if not next_page_found:\n",
    "            break\n",
    "\n",
    "    return \" | \".join(all_replies)\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chromedriver_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\Miki\\\\5508\\\\Project\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "service = Service(executable_path=chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "url = 'https://lihkg.com/search?q=%E6%AC%BA%E9%A8%99&sort=desc_create_time&type=thread'\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "data = []\n",
    "topics = driver.find_elements(By.CLASS_NAME, 'wQ4Ran7ySbKd8PdMeHZZR')\n",
    "\n",
    "for topic in topics:\n",
    "    title = topic.find_element(By.CSS_SELECTOR, 'span._20jopXBFHNQ9FUbcGHLcHH').text.strip()\n",
    "    username = topic.find_element(By.CSS_SELECTOR, 'span.CxY4XDSSItTeLVg0cKCN0').text.strip()\n",
    "    topic_url_element = topic.find_element(By.CSS_SELECTOR, 'a._2A_7bGY9QAXcGu1neEYDJB')\n",
    "    topic_url = topic_url_element.get_attribute('href')\n",
    "\n",
    "    driver.execute_script(\"window.open('{}');\".format(topic_url))\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')))\n",
    "\n",
    "    main_content_element = driver.find_element(By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')\n",
    "    main_content = main_content_element.text if main_content_element else \"Content not found\"\n",
    "\n",
    "    likes_element = driver.find_element(By.CSS_SELECTOR, 'label._1yxPOd27pAzF9olhItRDej')\n",
    "    likes = likes_element.text if likes_element else \"Likes not found\"\n",
    "\n",
    "    dislikes_element = driver.find_element(By.CSS_SELECTOR, 'label._2iRKJuMIV77zdwLRreUgLK')\n",
    "    dislikes = dislikes_element.text if dislikes_element else \"Dislikes not found\"\n",
    "\n",
    "    replies = scrape_replies(driver, topic_url)\n",
    "\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "    data.append([title, username, main_content, likes, dislikes, topic_url, replies])\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "csv_file_name = \"欺騙.csv\"\n",
    "\n",
    "with open(csv_file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Username\", \"Main Content\", \"Likes\", \"Dislikes\", \"URL\", \"All Replies\"])\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Data successfully written to {csv_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a52488e8-71dd-49a6-8e37-1afd2e7e6665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#行騙"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d2d23c6-f28b-4fb2-8dad-d06cf388b0ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to 行騙.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "def scrape_replies(driver, topic_url):\n",
    "    driver.get(topic_url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    all_replies = []\n",
    "\n",
    "    while True:\n",
    "        reply_elements = driver.find_elements(By.CSS_SELECTOR, 'div._36ZEkSvpdj_igmog0nluzh')\n",
    "        for reply_element in reply_elements:\n",
    "            reply_text = reply_element.text.replace(\"\\n\", \" \").strip()\n",
    "            all_replies.append(reply_text)\n",
    "\n",
    "        next_page_buttons = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/page/']\")\n",
    "        next_page_found = False\n",
    "        for button in next_page_buttons:\n",
    "            if button.text == \"下一頁\":\n",
    "                next_url = button.get_attribute('href')\n",
    "                driver.get(next_url)\n",
    "                time.sleep(5)  # Wait for the next page to load\n",
    "                next_page_found = True\n",
    "                break\n",
    "\n",
    "        if not next_page_found:\n",
    "            break\n",
    "\n",
    "    return \" | \".join(all_replies)\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chromedriver_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\Miki\\\\5508\\\\Project\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "service = Service(executable_path=chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "url = 'https://lihkg.com/search?q=%E8%A1%8C%E9%A8%99&sort=desc_create_time&type=thread'\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "data = []\n",
    "topics = driver.find_elements(By.CLASS_NAME, 'wQ4Ran7ySbKd8PdMeHZZR')\n",
    "\n",
    "for topic in topics:\n",
    "    title = topic.find_element(By.CSS_SELECTOR, 'span._20jopXBFHNQ9FUbcGHLcHH').text.strip()\n",
    "    username = topic.find_element(By.CSS_SELECTOR, 'span.CxY4XDSSItTeLVg0cKCN0').text.strip()\n",
    "    topic_url_element = topic.find_element(By.CSS_SELECTOR, 'a._2A_7bGY9QAXcGu1neEYDJB')\n",
    "    topic_url = topic_url_element.get_attribute('href')\n",
    "\n",
    "    driver.execute_script(\"window.open('{}');\".format(topic_url))\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')))\n",
    "\n",
    "    main_content_element = driver.find_element(By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')\n",
    "    main_content = main_content_element.text if main_content_element else \"Content not found\"\n",
    "\n",
    "    likes_element = driver.find_element(By.CSS_SELECTOR, 'label._1yxPOd27pAzF9olhItRDej')\n",
    "    likes = likes_element.text if likes_element else \"Likes not found\"\n",
    "\n",
    "    dislikes_element = driver.find_element(By.CSS_SELECTOR, 'label._2iRKJuMIV77zdwLRreUgLK')\n",
    "    dislikes = dislikes_element.text if dislikes_element else \"Dislikes not found\"\n",
    "\n",
    "    replies = scrape_replies(driver, topic_url)\n",
    "\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "    data.append([title, username, main_content, likes, dislikes, topic_url, replies])\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "csv_file_name = \"行騙.csv\"\n",
    "\n",
    "with open(csv_file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Username\", \"Main Content\", \"Likes\", \"Dislikes\", \"URL\", \"All Replies\"])\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Data successfully written to {csv_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dc5028e-de14-44a3-bd02-02486c4befa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#詐騙"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80f81c22-aeef-4923-8a1b-0da2aadf28e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to 詐騙.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "def scrape_replies(driver, topic_url):\n",
    "    driver.get(topic_url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    all_replies = []\n",
    "\n",
    "    while True:\n",
    "        reply_elements = driver.find_elements(By.CSS_SELECTOR, 'div._36ZEkSvpdj_igmog0nluzh')\n",
    "        for reply_element in reply_elements:\n",
    "            reply_text = reply_element.text.replace(\"\\n\", \" \").strip()\n",
    "            all_replies.append(reply_text)\n",
    "\n",
    "        next_page_buttons = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/page/']\")\n",
    "        next_page_found = False\n",
    "        for button in next_page_buttons:\n",
    "            if button.text == \"下一頁\":\n",
    "                next_url = button.get_attribute('href')\n",
    "                driver.get(next_url)\n",
    "                time.sleep(5)  # Wait for the next page to load\n",
    "                next_page_found = True\n",
    "                break\n",
    "\n",
    "        if not next_page_found:\n",
    "            break\n",
    "\n",
    "    return \" | \".join(all_replies)\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chromedriver_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\Miki\\\\5508\\\\Project\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "service = Service(executable_path=chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "url = 'https://lihkg.com/search?q=%E8%A9%90%E9%A8%99&sort=desc_reply_time&type=thread'\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "data = []\n",
    "topics = driver.find_elements(By.CLASS_NAME, 'wQ4Ran7ySbKd8PdMeHZZR')\n",
    "\n",
    "for topic in topics:\n",
    "    title = topic.find_element(By.CSS_SELECTOR, 'span._20jopXBFHNQ9FUbcGHLcHH').text.strip()\n",
    "    username = topic.find_element(By.CSS_SELECTOR, 'span.CxY4XDSSItTeLVg0cKCN0').text.strip()\n",
    "    topic_url_element = topic.find_element(By.CSS_SELECTOR, 'a._2A_7bGY9QAXcGu1neEYDJB')\n",
    "    topic_url = topic_url_element.get_attribute('href')\n",
    "\n",
    "    driver.execute_script(\"window.open('{}');\".format(topic_url))\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')))\n",
    "\n",
    "    main_content_element = driver.find_element(By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')\n",
    "    main_content = main_content_element.text if main_content_element else \"Content not found\"\n",
    "\n",
    "    likes_element = driver.find_element(By.CSS_SELECTOR, 'label._1yxPOd27pAzF9olhItRDej')\n",
    "    likes = likes_element.text if likes_element else \"Likes not found\"\n",
    "\n",
    "    dislikes_element = driver.find_element(By.CSS_SELECTOR, 'label._2iRKJuMIV77zdwLRreUgLK')\n",
    "    dislikes = dislikes_element.text if dislikes_element else \"Dislikes not found\"\n",
    "\n",
    "    replies = scrape_replies(driver, topic_url)\n",
    "\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "    data.append([title, username, main_content, likes, dislikes, topic_url, replies])\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "csv_file_name = \"詐騙.csv\"\n",
    "\n",
    "with open(csv_file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Username\", \"Main Content\", \"Likes\", \"Dislikes\", \"URL\", \"All Replies\"])\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Data successfully written to {csv_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6f46505-9049-4781-86fa-31eafdd346d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#欺詐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5ba8c7a-19bb-4893-b9f2-b539b34d9264",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to 欺詐.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "def scrape_replies(driver, topic_url):\n",
    "    driver.get(topic_url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    all_replies = []\n",
    "\n",
    "    while True:\n",
    "        reply_elements = driver.find_elements(By.CSS_SELECTOR, 'div._36ZEkSvpdj_igmog0nluzh')\n",
    "        for reply_element in reply_elements:\n",
    "            reply_text = reply_element.text.replace(\"\\n\", \" \").strip()\n",
    "            all_replies.append(reply_text)\n",
    "\n",
    "        next_page_buttons = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/page/']\")\n",
    "        next_page_found = False\n",
    "        for button in next_page_buttons:\n",
    "            if button.text == \"下一頁\":\n",
    "                next_url = button.get_attribute('href')\n",
    "                driver.get(next_url)\n",
    "                time.sleep(5)  # Wait for the next page to load\n",
    "                next_page_found = True\n",
    "                break\n",
    "\n",
    "        if not next_page_found:\n",
    "            break\n",
    "\n",
    "    return \" | \".join(all_replies)\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chromedriver_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\Miki\\\\5508\\\\Project\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "service = Service(executable_path=chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "url = 'https://lihkg.com/search?q=%E6%AC%BA%E8%A9%90&sort=desc_reply_time&type=thread'\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "data = []\n",
    "topics = driver.find_elements(By.CLASS_NAME, 'wQ4Ran7ySbKd8PdMeHZZR')\n",
    "\n",
    "for topic in topics:\n",
    "    title = topic.find_element(By.CSS_SELECTOR, 'span._20jopXBFHNQ9FUbcGHLcHH').text.strip()\n",
    "    username = topic.find_element(By.CSS_SELECTOR, 'span.CxY4XDSSItTeLVg0cKCN0').text.strip()\n",
    "    topic_url_element = topic.find_element(By.CSS_SELECTOR, 'a._2A_7bGY9QAXcGu1neEYDJB')\n",
    "    topic_url = topic_url_element.get_attribute('href')\n",
    "\n",
    "    driver.execute_script(\"window.open('{}');\".format(topic_url))\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')))\n",
    "\n",
    "    main_content_element = driver.find_element(By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')\n",
    "    main_content = main_content_element.text if main_content_element else \"Content not found\"\n",
    "\n",
    "    likes_element = driver.find_element(By.CSS_SELECTOR, 'label._1yxPOd27pAzF9olhItRDej')\n",
    "    likes = likes_element.text if likes_element else \"Likes not found\"\n",
    "\n",
    "    dislikes_element = driver.find_element(By.CSS_SELECTOR, 'label._2iRKJuMIV77zdwLRreUgLK')\n",
    "    dislikes = dislikes_element.text if dislikes_element else \"Dislikes not found\"\n",
    "\n",
    "    replies = scrape_replies(driver, topic_url)\n",
    "\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "    data.append([title, username, main_content, likes, dislikes, topic_url, replies])\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "csv_file_name = \"欺詐.csv\"\n",
    "\n",
    "with open(csv_file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Username\", \"Main Content\", \"Likes\", \"Dislikes\", \"URL\", \"All Replies\"])\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Data successfully written to {csv_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70e9d5b3-3cb5-4264-8538-0e1ee7244383",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#電騙"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0586829-335f-4b08-86a6-6677de76db20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to 電騙.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "def scrape_replies(driver, topic_url):\n",
    "    driver.get(topic_url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    all_replies = []\n",
    "\n",
    "    while True:\n",
    "        reply_elements = driver.find_elements(By.CSS_SELECTOR, 'div._36ZEkSvpdj_igmog0nluzh')\n",
    "        for reply_element in reply_elements:\n",
    "            reply_text = reply_element.text.replace(\"\\n\", \" \").strip()\n",
    "            all_replies.append(reply_text)\n",
    "\n",
    "        next_page_buttons = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/page/']\")\n",
    "        next_page_found = False\n",
    "        for button in next_page_buttons:\n",
    "            if button.text == \"下一頁\":\n",
    "                next_url = button.get_attribute('href')\n",
    "                driver.get(next_url)\n",
    "                time.sleep(5)  # Wait for the next page to load\n",
    "                next_page_found = True\n",
    "                break\n",
    "\n",
    "        if not next_page_found:\n",
    "            break\n",
    "\n",
    "    return \" | \".join(all_replies)\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chromedriver_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\Miki\\\\5508\\\\Project\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "service = Service(executable_path=chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "url = 'https://lihkg.com/search?q=%E9%9B%BB%E9%A8%99&sort=desc_reply_time&type=thread'\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "data = []\n",
    "topics = driver.find_elements(By.CLASS_NAME, 'wQ4Ran7ySbKd8PdMeHZZR')\n",
    "\n",
    "for topic in topics:\n",
    "    title = topic.find_element(By.CSS_SELECTOR, 'span._20jopXBFHNQ9FUbcGHLcHH').text.strip()\n",
    "    username = topic.find_element(By.CSS_SELECTOR, 'span.CxY4XDSSItTeLVg0cKCN0').text.strip()\n",
    "    topic_url_element = topic.find_element(By.CSS_SELECTOR, 'a._2A_7bGY9QAXcGu1neEYDJB')\n",
    "    topic_url = topic_url_element.get_attribute('href')\n",
    "\n",
    "    driver.execute_script(\"window.open('{}');\".format(topic_url))\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')))\n",
    "\n",
    "    main_content_element = driver.find_element(By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')\n",
    "    main_content = main_content_element.text if main_content_element else \"Content not found\"\n",
    "\n",
    "    likes_element = driver.find_element(By.CSS_SELECTOR, 'label._1yxPOd27pAzF9olhItRDej')\n",
    "    likes = likes_element.text if likes_element else \"Likes not found\"\n",
    "\n",
    "    dislikes_element = driver.find_element(By.CSS_SELECTOR, 'label._2iRKJuMIV77zdwLRreUgLK')\n",
    "    dislikes = dislikes_element.text if dislikes_element else \"Dislikes not found\"\n",
    "\n",
    "    replies = scrape_replies(driver, topic_url)\n",
    "\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "    data.append([title, username, main_content, likes, dislikes, topic_url, replies])\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "csv_file_name = \"電騙.csv\"\n",
    "\n",
    "with open(csv_file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Username\", \"Main Content\", \"Likes\", \"Dislikes\", \"URL\", \"All Replies\"])\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Data successfully written to {csv_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b73042ce-0efd-4bfa-ac50-e9d8f3587a8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#騙徒"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12ba0d03-ad5b-48f2-8192-0f99ea24eefa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to 騙徒.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "def scrape_replies(driver, topic_url):\n",
    "    driver.get(topic_url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    all_replies = []\n",
    "\n",
    "    while True:\n",
    "        reply_elements = driver.find_elements(By.CSS_SELECTOR, 'div._36ZEkSvpdj_igmog0nluzh')\n",
    "        for reply_element in reply_elements:\n",
    "            reply_text = reply_element.text.replace(\"\\n\", \" \").strip()\n",
    "            all_replies.append(reply_text)\n",
    "\n",
    "        next_page_buttons = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/page/']\")\n",
    "        next_page_found = False\n",
    "        for button in next_page_buttons:\n",
    "            if button.text == \"下一頁\":\n",
    "                next_url = button.get_attribute('href')\n",
    "                driver.get(next_url)\n",
    "                time.sleep(5)  # Wait for the next page to load\n",
    "                next_page_found = True\n",
    "                break\n",
    "\n",
    "        if not next_page_found:\n",
    "            break\n",
    "\n",
    "    return \" | \".join(all_replies)\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chromedriver_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\Miki\\\\5508\\\\Project\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "service = Service(executable_path=chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "url = 'https://lihkg.com/search?q=%E9%A8%99%E5%BE%92&sort=desc_create_time&type=thread'\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "data = []\n",
    "topics = driver.find_elements(By.CLASS_NAME, 'wQ4Ran7ySbKd8PdMeHZZR')\n",
    "\n",
    "for topic in topics:\n",
    "    title = topic.find_element(By.CSS_SELECTOR, 'span._20jopXBFHNQ9FUbcGHLcHH').text.strip()\n",
    "    username = topic.find_element(By.CSS_SELECTOR, 'span.CxY4XDSSItTeLVg0cKCN0').text.strip()\n",
    "    topic_url_element = topic.find_element(By.CSS_SELECTOR, 'a._2A_7bGY9QAXcGu1neEYDJB')\n",
    "    topic_url = topic_url_element.get_attribute('href')\n",
    "\n",
    "    driver.execute_script(\"window.open('{}');\".format(topic_url))\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')))\n",
    "\n",
    "    main_content_element = driver.find_element(By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')\n",
    "    main_content = main_content_element.text if main_content_element else \"Content not found\"\n",
    "\n",
    "    likes_element = driver.find_element(By.CSS_SELECTOR, 'label._1yxPOd27pAzF9olhItRDej')\n",
    "    likes = likes_element.text if likes_element else \"Likes not found\"\n",
    "\n",
    "    dislikes_element = driver.find_element(By.CSS_SELECTOR, 'label._2iRKJuMIV77zdwLRreUgLK')\n",
    "    dislikes = dislikes_element.text if dislikes_element else \"Dislikes not found\"\n",
    "\n",
    "    replies = scrape_replies(driver, topic_url)\n",
    "\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "    data.append([title, username, main_content, likes, dislikes, topic_url, replies])\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "csv_file_name = \"騙徒.csv\"\n",
    "\n",
    "with open(csv_file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Username\", \"Main Content\", \"Likes\", \"Dislikes\", \"URL\", \"All Replies\"])\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Data successfully written to {csv_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6507ee4b-cf93-4c44-81eb-be879d830157",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#電詐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85af4754-f52a-4b2a-8793-f91dfe73507b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to 電詐.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "def scrape_replies(driver, topic_url):\n",
    "    driver.get(topic_url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    all_replies = []\n",
    "\n",
    "    while True:\n",
    "        reply_elements = driver.find_elements(By.CSS_SELECTOR, 'div._36ZEkSvpdj_igmog0nluzh')\n",
    "        for reply_element in reply_elements:\n",
    "            reply_text = reply_element.text.replace(\"\\n\", \" \").strip()\n",
    "            all_replies.append(reply_text)\n",
    "\n",
    "        next_page_buttons = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/page/']\")\n",
    "        next_page_found = False\n",
    "        for button in next_page_buttons:\n",
    "            if button.text == \"下一頁\":\n",
    "                next_url = button.get_attribute('href')\n",
    "                driver.get(next_url)\n",
    "                time.sleep(5)  # Wait for the next page to load\n",
    "                next_page_found = True\n",
    "                break\n",
    "\n",
    "        if not next_page_found:\n",
    "            break\n",
    "\n",
    "    return \" | \".join(all_replies)\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chromedriver_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\Miki\\\\5508\\\\Project\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "service = Service(executable_path=chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "url = 'https://lihkg.com/search?q=%E9%9B%BB%E8%A9%90&sort=desc_create_time&type=thread'\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "data = []\n",
    "topics = driver.find_elements(By.CLASS_NAME, 'wQ4Ran7ySbKd8PdMeHZZR')\n",
    "\n",
    "for topic in topics:\n",
    "    title = topic.find_element(By.CSS_SELECTOR, 'span._20jopXBFHNQ9FUbcGHLcHH').text.strip()\n",
    "    username = topic.find_element(By.CSS_SELECTOR, 'span.CxY4XDSSItTeLVg0cKCN0').text.strip()\n",
    "    topic_url_element = topic.find_element(By.CSS_SELECTOR, 'a._2A_7bGY9QAXcGu1neEYDJB')\n",
    "    topic_url = topic_url_element.get_attribute('href')\n",
    "\n",
    "    driver.execute_script(\"window.open('{}');\".format(topic_url))\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')))\n",
    "\n",
    "    main_content_element = driver.find_element(By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')\n",
    "    main_content = main_content_element.text if main_content_element else \"Content not found\"\n",
    "\n",
    "    likes_element = driver.find_element(By.CSS_SELECTOR, 'label._1yxPOd27pAzF9olhItRDej')\n",
    "    likes = likes_element.text if likes_element else \"Likes not found\"\n",
    "\n",
    "    dislikes_element = driver.find_element(By.CSS_SELECTOR, 'label._2iRKJuMIV77zdwLRreUgLK')\n",
    "    dislikes = dislikes_element.text if dislikes_element else \"Dislikes not found\"\n",
    "\n",
    "    replies = scrape_replies(driver, topic_url)\n",
    "\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "    data.append([title, username, main_content, likes, dislikes, topic_url, replies])\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "csv_file_name = \"電詐.csv\"\n",
    "\n",
    "with open(csv_file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Username\", \"Main Content\", \"Likes\", \"Dislikes\", \"URL\", \"All Replies\"])\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Data successfully written to {csv_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7abe678d-4c9f-4cd0-bed5-2fe57e076401",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#騙錢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12fd461f-e393-4a8c-8410-3a03900b7564",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to 騙錢.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "def scrape_replies(driver, topic_url):\n",
    "    driver.get(topic_url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    all_replies = []\n",
    "\n",
    "    while True:\n",
    "        reply_elements = driver.find_elements(By.CSS_SELECTOR, 'div._36ZEkSvpdj_igmog0nluzh')\n",
    "        for reply_element in reply_elements:\n",
    "            reply_text = reply_element.text.replace(\"\\n\", \" \").strip()\n",
    "            all_replies.append(reply_text)\n",
    "\n",
    "        next_page_buttons = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/page/']\")\n",
    "        next_page_found = False\n",
    "        for button in next_page_buttons:\n",
    "            if button.text == \"下一頁\":\n",
    "                next_url = button.get_attribute('href')\n",
    "                driver.get(next_url)\n",
    "                time.sleep(5)  # Wait for the next page to load\n",
    "                next_page_found = True\n",
    "                break\n",
    "\n",
    "        if not next_page_found:\n",
    "            break\n",
    "\n",
    "    return \" | \".join(all_replies)\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chromedriver_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\Miki\\\\5508\\\\Project\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "service = Service(executable_path=chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "url = 'https://lihkg.com/search?q=%E9%A8%99%E9%8C%A2&sort=desc_create_time&type=thread'\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "data = []\n",
    "topics = driver.find_elements(By.CLASS_NAME, 'wQ4Ran7ySbKd8PdMeHZZR')\n",
    "\n",
    "for topic in topics:\n",
    "    title = topic.find_element(By.CSS_SELECTOR, 'span._20jopXBFHNQ9FUbcGHLcHH').text.strip()\n",
    "    username = topic.find_element(By.CSS_SELECTOR, 'span.CxY4XDSSItTeLVg0cKCN0').text.strip()\n",
    "    topic_url_element = topic.find_element(By.CSS_SELECTOR, 'a._2A_7bGY9QAXcGu1neEYDJB')\n",
    "    topic_url = topic_url_element.get_attribute('href')\n",
    "\n",
    "    driver.execute_script(\"window.open('{}');\".format(topic_url))\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')))\n",
    "\n",
    "    main_content_element = driver.find_element(By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')\n",
    "    main_content = main_content_element.text if main_content_element else \"Content not found\"\n",
    "\n",
    "    likes_element = driver.find_element(By.CSS_SELECTOR, 'label._1yxPOd27pAzF9olhItRDej')\n",
    "    likes = likes_element.text if likes_element else \"Likes not found\"\n",
    "\n",
    "    dislikes_element = driver.find_element(By.CSS_SELECTOR, 'label._2iRKJuMIV77zdwLRreUgLK')\n",
    "    dislikes = dislikes_element.text if dislikes_element else \"Dislikes not found\"\n",
    "\n",
    "    replies = scrape_replies(driver, topic_url)\n",
    "\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "    data.append([title, username, main_content, likes, dislikes, topic_url, replies])\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "csv_file_name = \"騙錢.csv\"\n",
    "\n",
    "with open(csv_file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Username\", \"Main Content\", \"Likes\", \"Dislikes\", \"URL\", \"All Replies\"])\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Data successfully written to {csv_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2864fd85-58c5-499b-b0c2-729966279a46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#呃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b22086e3-88b3-45cf-8d35-b5d6081f2301",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to 呃.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "def scrape_replies(driver, topic_url):\n",
    "    driver.get(topic_url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    all_replies = []\n",
    "\n",
    "    while True:\n",
    "        reply_elements = driver.find_elements(By.CSS_SELECTOR, 'div._36ZEkSvpdj_igmog0nluzh')\n",
    "        for reply_element in reply_elements:\n",
    "            reply_text = reply_element.text.replace(\"\\n\", \" \").strip()\n",
    "            all_replies.append(reply_text)\n",
    "\n",
    "        next_page_buttons = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/page/']\")\n",
    "        next_page_found = False\n",
    "        for button in next_page_buttons:\n",
    "            if button.text == \"下一頁\":\n",
    "                next_url = button.get_attribute('href')\n",
    "                driver.get(next_url)\n",
    "                time.sleep(5)  # Wait for the next page to load\n",
    "                next_page_found = True\n",
    "                break\n",
    "\n",
    "        if not next_page_found:\n",
    "            break\n",
    "\n",
    "    return \" | \".join(all_replies)\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chromedriver_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\Miki\\\\5508\\\\Project\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "service = Service(executable_path=chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "url = 'https://lihkg.com/search?q=%E5%91%83&sort=desc_create_time&type=thread'\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "data = []\n",
    "topics = driver.find_elements(By.CLASS_NAME, 'wQ4Ran7ySbKd8PdMeHZZR')\n",
    "\n",
    "for topic in topics:\n",
    "    title = topic.find_element(By.CSS_SELECTOR, 'span._20jopXBFHNQ9FUbcGHLcHH').text.strip()\n",
    "    username = topic.find_element(By.CSS_SELECTOR, 'span.CxY4XDSSItTeLVg0cKCN0').text.strip()\n",
    "    topic_url_element = topic.find_element(By.CSS_SELECTOR, 'a._2A_7bGY9QAXcGu1neEYDJB')\n",
    "    topic_url = topic_url_element.get_attribute('href')\n",
    "\n",
    "    driver.execute_script(\"window.open('{}');\".format(topic_url))\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')))\n",
    "\n",
    "    main_content_element = driver.find_element(By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')\n",
    "    main_content = main_content_element.text if main_content_element else \"Content not found\"\n",
    "\n",
    "    likes_element = driver.find_element(By.CSS_SELECTOR, 'label._1yxPOd27pAzF9olhItRDej')\n",
    "    likes = likes_element.text if likes_element else \"Likes not found\"\n",
    "\n",
    "    dislikes_element = driver.find_element(By.CSS_SELECTOR, 'label._2iRKJuMIV77zdwLRreUgLK')\n",
    "    dislikes = dislikes_element.text if dislikes_element else \"Dislikes not found\"\n",
    "\n",
    "    replies = scrape_replies(driver, topic_url)\n",
    "\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "    data.append([title, username, main_content, likes, dislikes, topic_url, replies])\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "csv_file_name = \"呃.csv\"\n",
    "\n",
    "with open(csv_file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Username\", \"Main Content\", \"Likes\", \"Dislikes\", \"URL\", \"All Replies\"])\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Data successfully written to {csv_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90df6298-7bca-4d19-9823-1955e2fe7238",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#呃人"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d73baa1a-43a7-4d05-947d-02c0bf00dff4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to 呃人.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "def scrape_replies(driver, topic_url):\n",
    "    driver.get(topic_url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    all_replies = []\n",
    "\n",
    "    while True:\n",
    "        reply_elements = driver.find_elements(By.CSS_SELECTOR, 'div._36ZEkSvpdj_igmog0nluzh')\n",
    "        for reply_element in reply_elements:\n",
    "            reply_text = reply_element.text.replace(\"\\n\", \" \").strip()\n",
    "            all_replies.append(reply_text)\n",
    "\n",
    "        next_page_buttons = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/page/']\")\n",
    "        next_page_found = False\n",
    "        for button in next_page_buttons:\n",
    "            if button.text == \"下一頁\":\n",
    "                next_url = button.get_attribute('href')\n",
    "                driver.get(next_url)\n",
    "                time.sleep(5)  # Wait for the next page to load\n",
    "                next_page_found = True\n",
    "                break\n",
    "\n",
    "        if not next_page_found:\n",
    "            break\n",
    "\n",
    "    return \" | \".join(all_replies)\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chromedriver_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\Miki\\\\5508\\\\Project\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "service = Service(executable_path=chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "url = 'https://lihkg.com/search?q=%E5%91%83%E4%BA%BA&sort=desc_create_time&type=thread'\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "data = []\n",
    "topics = driver.find_elements(By.CLASS_NAME, 'wQ4Ran7ySbKd8PdMeHZZR')\n",
    "\n",
    "for topic in topics:\n",
    "    title = topic.find_element(By.CSS_SELECTOR, 'span._20jopXBFHNQ9FUbcGHLcHH').text.strip()\n",
    "    username = topic.find_element(By.CSS_SELECTOR, 'span.CxY4XDSSItTeLVg0cKCN0').text.strip()\n",
    "    topic_url_element = topic.find_element(By.CSS_SELECTOR, 'a._2A_7bGY9QAXcGu1neEYDJB')\n",
    "    topic_url = topic_url_element.get_attribute('href')\n",
    "\n",
    "    driver.execute_script(\"window.open('{}');\".format(topic_url))\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')))\n",
    "\n",
    "    main_content_element = driver.find_element(By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')\n",
    "    main_content = main_content_element.text if main_content_element else \"Content not found\"\n",
    "\n",
    "    likes_element = driver.find_element(By.CSS_SELECTOR, 'label._1yxPOd27pAzF9olhItRDej')\n",
    "    likes = likes_element.text if likes_element else \"Likes not found\"\n",
    "\n",
    "    dislikes_element = driver.find_element(By.CSS_SELECTOR, 'label._2iRKJuMIV77zdwLRreUgLK')\n",
    "    dislikes = dislikes_element.text if dislikes_element else \"Dislikes not found\"\n",
    "\n",
    "    replies = scrape_replies(driver, topic_url)\n",
    "\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "    data.append([title, username, main_content, likes, dislikes, topic_url, replies])\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "csv_file_name = \"呃人.csv\"\n",
    "\n",
    "with open(csv_file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Username\", \"Main Content\", \"Likes\", \"Dislikes\", \"URL\", \"All Replies\"])\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Data successfully written to {csv_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14b723e8-179c-41ba-921f-adb6e4fe30d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#呃錢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "905460b2-0b48-46e3-a418-4a9d36d0e7f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to 呃錢.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "def scrape_replies(driver, topic_url):\n",
    "    driver.get(topic_url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    all_replies = []\n",
    "\n",
    "    while True:\n",
    "        reply_elements = driver.find_elements(By.CSS_SELECTOR, 'div._36ZEkSvpdj_igmog0nluzh')\n",
    "        for reply_element in reply_elements:\n",
    "            reply_text = reply_element.text.replace(\"\\n\", \" \").strip()\n",
    "            all_replies.append(reply_text)\n",
    "\n",
    "        next_page_buttons = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/page/']\")\n",
    "        next_page_found = False\n",
    "        for button in next_page_buttons:\n",
    "            if button.text == \"下一頁\":\n",
    "                next_url = button.get_attribute('href')\n",
    "                driver.get(next_url)\n",
    "                time.sleep(5)  # Wait for the next page to load\n",
    "                next_page_found = True\n",
    "                break\n",
    "\n",
    "        if not next_page_found:\n",
    "            break\n",
    "\n",
    "    return \" | \".join(all_replies)\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chromedriver_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\Miki\\\\5508\\\\Project\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "service = Service(executable_path=chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "url = 'https://lihkg.com/search?q=%E5%91%83%E9%8C%A2&sort=desc_create_time&type=thread'\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "data = []\n",
    "topics = driver.find_elements(By.CLASS_NAME, 'wQ4Ran7ySbKd8PdMeHZZR')\n",
    "\n",
    "for topic in topics:\n",
    "    title = topic.find_element(By.CSS_SELECTOR, 'span._20jopXBFHNQ9FUbcGHLcHH').text.strip()\n",
    "    username = topic.find_element(By.CSS_SELECTOR, 'span.CxY4XDSSItTeLVg0cKCN0').text.strip()\n",
    "    topic_url_element = topic.find_element(By.CSS_SELECTOR, 'a._2A_7bGY9QAXcGu1neEYDJB')\n",
    "    topic_url = topic_url_element.get_attribute('href')\n",
    "\n",
    "    driver.execute_script(\"window.open('{}');\".format(topic_url))\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')))\n",
    "\n",
    "    main_content_element = driver.find_element(By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')\n",
    "    main_content = main_content_element.text if main_content_element else \"Content not found\"\n",
    "\n",
    "    likes_element = driver.find_element(By.CSS_SELECTOR, 'label._1yxPOd27pAzF9olhItRDej')\n",
    "    likes = likes_element.text if likes_element else \"Likes not found\"\n",
    "\n",
    "    dislikes_element = driver.find_element(By.CSS_SELECTOR, 'label._2iRKJuMIV77zdwLRreUgLK')\n",
    "    dislikes = dislikes_element.text if dislikes_element else \"Dislikes not found\"\n",
    "\n",
    "    replies = scrape_replies(driver, topic_url)\n",
    "\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "    data.append([title, username, main_content, likes, dislikes, topic_url, replies])\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "csv_file_name = \"呃錢.csv\"\n",
    "\n",
    "with open(csv_file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Username\", \"Main Content\", \"Likes\", \"Dislikes\", \"URL\", \"All Replies\"])\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Data successfully written to {csv_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "074e8662-8043-4750-95fa-ac9f24c1d08d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#電話騙案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eb5a2a9-0302-417c-a213-e55d2c90f130",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to 電話騙案.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "def scrape_replies(driver, topic_url):\n",
    "    driver.get(topic_url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    all_replies = []\n",
    "\n",
    "    while True:\n",
    "        reply_elements = driver.find_elements(By.CSS_SELECTOR, 'div._36ZEkSvpdj_igmog0nluzh')\n",
    "        for reply_element in reply_elements:\n",
    "            reply_text = reply_element.text.replace(\"\\n\", \" \").strip()\n",
    "            all_replies.append(reply_text)\n",
    "\n",
    "        next_page_buttons = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/page/']\")\n",
    "        next_page_found = False\n",
    "        for button in next_page_buttons:\n",
    "            if button.text == \"下一頁\":\n",
    "                next_url = button.get_attribute('href')\n",
    "                driver.get(next_url)\n",
    "                time.sleep(5)  # Wait for the next page to load\n",
    "                next_page_found = True\n",
    "                break\n",
    "\n",
    "        if not next_page_found:\n",
    "            break\n",
    "\n",
    "    return \" | \".join(all_replies)\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chromedriver_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\Miki\\\\5508\\\\Project\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "service = Service(executable_path=chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "url = 'https://lihkg.com/search?q=%E9%9B%BB%E8%A9%B1%E9%A8%99%E6%A1%88&sort=desc_create_time&type=thread'\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "data = []\n",
    "topics = driver.find_elements(By.CLASS_NAME, 'wQ4Ran7ySbKd8PdMeHZZR')\n",
    "\n",
    "for topic in topics:\n",
    "    title = topic.find_element(By.CSS_SELECTOR, 'span._20jopXBFHNQ9FUbcGHLcHH').text.strip()\n",
    "    username = topic.find_element(By.CSS_SELECTOR, 'span.CxY4XDSSItTeLVg0cKCN0').text.strip()\n",
    "    topic_url_element = topic.find_element(By.CSS_SELECTOR, 'a._2A_7bGY9QAXcGu1neEYDJB')\n",
    "    topic_url = topic_url_element.get_attribute('href')\n",
    "\n",
    "    driver.execute_script(\"window.open('{}');\".format(topic_url))\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')))\n",
    "\n",
    "    main_content_element = driver.find_element(By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')\n",
    "    main_content = main_content_element.text if main_content_element else \"Content not found\"\n",
    "\n",
    "    likes_element = driver.find_element(By.CSS_SELECTOR, 'label._1yxPOd27pAzF9olhItRDej')\n",
    "    likes = likes_element.text if likes_element else \"Likes not found\"\n",
    "\n",
    "    dislikes_element = driver.find_element(By.CSS_SELECTOR, 'label._2iRKJuMIV77zdwLRreUgLK')\n",
    "    dislikes = dislikes_element.text if dislikes_element else \"Dislikes not found\"\n",
    "\n",
    "    replies = scrape_replies(driver, topic_url)\n",
    "\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "    data.append([title, username, main_content, likes, dislikes, topic_url, replies])\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "csv_file_name = \"電話騙案.csv\"\n",
    "\n",
    "with open(csv_file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Username\", \"Main Content\", \"Likes\", \"Dislikes\", \"URL\", \"All Replies\"])\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Data successfully written to {csv_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e9032c5-e8eb-47c1-9004-509c23353d73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#網上騙案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac9d5c4f-2a50-44d3-80fd-2ad2eafac126",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to 網上騙案.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "def scrape_replies(driver, topic_url):\n",
    "    driver.get(topic_url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    all_replies = []\n",
    "\n",
    "    while True:\n",
    "        reply_elements = driver.find_elements(By.CSS_SELECTOR, 'div._36ZEkSvpdj_igmog0nluzh')\n",
    "        for reply_element in reply_elements:\n",
    "            reply_text = reply_element.text.replace(\"\\n\", \" \").strip()\n",
    "            all_replies.append(reply_text)\n",
    "\n",
    "        next_page_buttons = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/page/']\")\n",
    "        next_page_found = False\n",
    "        for button in next_page_buttons:\n",
    "            if button.text == \"下一頁\":\n",
    "                next_url = button.get_attribute('href')\n",
    "                driver.get(next_url)\n",
    "                time.sleep(5)  # Wait for the next page to load\n",
    "                next_page_found = True\n",
    "                break\n",
    "\n",
    "        if not next_page_found:\n",
    "            break\n",
    "\n",
    "    return \" | \".join(all_replies)\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chromedriver_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\Miki\\\\5508\\\\Project\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "service = Service(executable_path=chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "url = 'https://lihkg.com/search?q=%E7%B6%B2%E4%B8%8A%E9%A8%99%E6%A1%88&sort=desc_create_time&type=thread'\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "data = []\n",
    "topics = driver.find_elements(By.CLASS_NAME, 'wQ4Ran7ySbKd8PdMeHZZR')\n",
    "\n",
    "for topic in topics:\n",
    "    title = topic.find_element(By.CSS_SELECTOR, 'span._20jopXBFHNQ9FUbcGHLcHH').text.strip()\n",
    "    username = topic.find_element(By.CSS_SELECTOR, 'span.CxY4XDSSItTeLVg0cKCN0').text.strip()\n",
    "    topic_url_element = topic.find_element(By.CSS_SELECTOR, 'a._2A_7bGY9QAXcGu1neEYDJB')\n",
    "    topic_url = topic_url_element.get_attribute('href')\n",
    "\n",
    "    driver.execute_script(\"window.open('{}');\".format(topic_url))\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')))\n",
    "\n",
    "    main_content_element = driver.find_element(By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')\n",
    "    main_content = main_content_element.text if main_content_element else \"Content not found\"\n",
    "\n",
    "    likes_element = driver.find_element(By.CSS_SELECTOR, 'label._1yxPOd27pAzF9olhItRDej')\n",
    "    likes = likes_element.text if likes_element else \"Likes not found\"\n",
    "\n",
    "    dislikes_element = driver.find_element(By.CSS_SELECTOR, 'label._2iRKJuMIV77zdwLRreUgLK')\n",
    "    dislikes = dislikes_element.text if dislikes_element else \"Dislikes not found\"\n",
    "\n",
    "    replies = scrape_replies(driver, topic_url)\n",
    "\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "    data.append([title, username, main_content, likes, dislikes, topic_url, replies])\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "csv_file_name = \"網上騙案.csv\"\n",
    "\n",
    "with open(csv_file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Username\", \"Main Content\", \"Likes\", \"Dislikes\", \"URL\", \"All Replies\"])\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Data successfully written to {csv_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6844275-980a-47d0-8a66-147562e459af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#網上呃錢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d746ece-331b-46dc-b199-651a9ed2804a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to 網上呃錢.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "def scrape_replies(driver, topic_url):\n",
    "    driver.get(topic_url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    all_replies = []\n",
    "\n",
    "    while True:\n",
    "        reply_elements = driver.find_elements(By.CSS_SELECTOR, 'div._36ZEkSvpdj_igmog0nluzh')\n",
    "        for reply_element in reply_elements:\n",
    "            reply_text = reply_element.text.replace(\"\\n\", \" \").strip()\n",
    "            all_replies.append(reply_text)\n",
    "\n",
    "        next_page_buttons = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/page/']\")\n",
    "        next_page_found = False\n",
    "        for button in next_page_buttons:\n",
    "            if button.text == \"下一頁\":\n",
    "                next_url = button.get_attribute('href')\n",
    "                driver.get(next_url)\n",
    "                time.sleep(5)  # Wait for the next page to load\n",
    "                next_page_found = True\n",
    "                break\n",
    "\n",
    "        if not next_page_found:\n",
    "            break\n",
    "\n",
    "    return \" | \".join(all_replies)\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chromedriver_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\Miki\\\\5508\\\\Project\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "service = Service(executable_path=chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "url = 'https://lihkg.com/search?q=%E7%B6%B2%E4%B8%8A%E5%91%83%E9%8C%A2&sort=desc_create_time&type=thread'\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "data = []\n",
    "topics = driver.find_elements(By.CLASS_NAME, 'wQ4Ran7ySbKd8PdMeHZZR')\n",
    "\n",
    "for topic in topics:\n",
    "    title = topic.find_element(By.CSS_SELECTOR, 'span._20jopXBFHNQ9FUbcGHLcHH').text.strip()\n",
    "    username = topic.find_element(By.CSS_SELECTOR, 'span.CxY4XDSSItTeLVg0cKCN0').text.strip()\n",
    "    topic_url_element = topic.find_element(By.CSS_SELECTOR, 'a._2A_7bGY9QAXcGu1neEYDJB')\n",
    "    topic_url = topic_url_element.get_attribute('href')\n",
    "\n",
    "    driver.execute_script(\"window.open('{}');\".format(topic_url))\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')))\n",
    "\n",
    "    main_content_element = driver.find_element(By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')\n",
    "    main_content = main_content_element.text if main_content_element else \"Content not found\"\n",
    "\n",
    "    likes_element = driver.find_element(By.CSS_SELECTOR, 'label._1yxPOd27pAzF9olhItRDej')\n",
    "    likes = likes_element.text if likes_element else \"Likes not found\"\n",
    "\n",
    "    dislikes_element = driver.find_element(By.CSS_SELECTOR, 'label._2iRKJuMIV77zdwLRreUgLK')\n",
    "    dislikes = dislikes_element.text if dislikes_element else \"Dislikes not found\"\n",
    "\n",
    "    replies = scrape_replies(driver, topic_url)\n",
    "\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "    data.append([title, username, main_content, likes, dislikes, topic_url, replies])\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "csv_file_name = \"網上呃錢.csv\"\n",
    "\n",
    "with open(csv_file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Username\", \"Main Content\", \"Likes\", \"Dislikes\", \"URL\", \"All Replies\"])\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Data successfully written to {csv_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6a29035-dda5-41d3-99e6-cad46e9f22e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#網上詐騙"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3ee0228-3c70-4f65-83c9-17b99db56cae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to 網上詐騙.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "def scrape_replies(driver, topic_url):\n",
    "    driver.get(topic_url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    all_replies = []\n",
    "\n",
    "    while True:\n",
    "        reply_elements = driver.find_elements(By.CSS_SELECTOR, 'div._36ZEkSvpdj_igmog0nluzh')\n",
    "        for reply_element in reply_elements:\n",
    "            reply_text = reply_element.text.replace(\"\\n\", \" \").strip()\n",
    "            all_replies.append(reply_text)\n",
    "\n",
    "        next_page_buttons = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/page/']\")\n",
    "        next_page_found = False\n",
    "        for button in next_page_buttons:\n",
    "            if button.text == \"下一頁\":\n",
    "                next_url = button.get_attribute('href')\n",
    "                driver.get(next_url)\n",
    "                time.sleep(5)  # Wait for the next page to load\n",
    "                next_page_found = True\n",
    "                break\n",
    "\n",
    "        if not next_page_found:\n",
    "            break\n",
    "\n",
    "    return \" | \".join(all_replies)\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chromedriver_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\Miki\\\\5508\\\\Project\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "service = Service(executable_path=chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "url = 'https://lihkg.com/search?q=%E7%B6%B2%E4%B8%8A%E8%A9%90%E9%A8%99&sort=desc_create_time&type=thread'\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "data = []\n",
    "topics = driver.find_elements(By.CLASS_NAME, 'wQ4Ran7ySbKd8PdMeHZZR')\n",
    "\n",
    "for topic in topics:\n",
    "    title = topic.find_element(By.CSS_SELECTOR, 'span._20jopXBFHNQ9FUbcGHLcHH').text.strip()\n",
    "    username = topic.find_element(By.CSS_SELECTOR, 'span.CxY4XDSSItTeLVg0cKCN0').text.strip()\n",
    "    topic_url_element = topic.find_element(By.CSS_SELECTOR, 'a._2A_7bGY9QAXcGu1neEYDJB')\n",
    "    topic_url = topic_url_element.get_attribute('href')\n",
    "\n",
    "    driver.execute_script(\"window.open('{}');\".format(topic_url))\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')))\n",
    "\n",
    "    main_content_element = driver.find_element(By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')\n",
    "    main_content = main_content_element.text if main_content_element else \"Content not found\"\n",
    "\n",
    "    likes_element = driver.find_element(By.CSS_SELECTOR, 'label._1yxPOd27pAzF9olhItRDej')\n",
    "    likes = likes_element.text if likes_element else \"Likes not found\"\n",
    "\n",
    "    dislikes_element = driver.find_element(By.CSS_SELECTOR, 'label._2iRKJuMIV77zdwLRreUgLK')\n",
    "    dislikes = dislikes_element.text if dislikes_element else \"Dislikes not found\"\n",
    "\n",
    "    replies = scrape_replies(driver, topic_url)\n",
    "\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "    data.append([title, username, main_content, likes, dislikes, topic_url, replies])\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "csv_file_name = \"網上詐騙.csv\"\n",
    "\n",
    "with open(csv_file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Username\", \"Main Content\", \"Likes\", \"Dislikes\", \"URL\", \"All Replies\"])\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Data successfully written to {csv_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05eb3db4-253c-4514-bbbd-1e60ddddec1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#騙徒手法層出不窮"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7695f6d5-2cd0-404e-98fa-add81ab9c482",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to 騙徒手法層出不窮.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "def scrape_replies(driver, topic_url):\n",
    "    driver.get(topic_url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    all_replies = []\n",
    "\n",
    "    while True:\n",
    "        reply_elements = driver.find_elements(By.CSS_SELECTOR, 'div._36ZEkSvpdj_igmog0nluzh')\n",
    "        for reply_element in reply_elements:\n",
    "            reply_text = reply_element.text.replace(\"\\n\", \" \").strip()\n",
    "            all_replies.append(reply_text)\n",
    "\n",
    "        next_page_buttons = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/page/']\")\n",
    "        next_page_found = False\n",
    "        for button in next_page_buttons:\n",
    "            if button.text == \"下一頁\":\n",
    "                next_url = button.get_attribute('href')\n",
    "                driver.get(next_url)\n",
    "                time.sleep(5)  # Wait for the next page to load\n",
    "                next_page_found = True\n",
    "                break\n",
    "\n",
    "        if not next_page_found:\n",
    "            break\n",
    "\n",
    "    return \" | \".join(all_replies)\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chromedriver_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\Miki\\\\5508\\\\Project\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "service = Service(executable_path=chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "url = 'https://lihkg.com/search?q=%E9%A8%99%E5%BE%92%E6%89%8B%E6%B3%95%E5%B1%A4%E5%87%BA%E4%B8%8D%E7%AA%AE&sort=desc_create_time&type=thread'\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "data = []\n",
    "topics = driver.find_elements(By.CLASS_NAME, 'wQ4Ran7ySbKd8PdMeHZZR')\n",
    "\n",
    "for topic in topics:\n",
    "    title = topic.find_element(By.CSS_SELECTOR, 'span._20jopXBFHNQ9FUbcGHLcHH').text.strip()\n",
    "    username = topic.find_element(By.CSS_SELECTOR, 'span.CxY4XDSSItTeLVg0cKCN0').text.strip()\n",
    "    topic_url_element = topic.find_element(By.CSS_SELECTOR, 'a._2A_7bGY9QAXcGu1neEYDJB')\n",
    "    topic_url = topic_url_element.get_attribute('href')\n",
    "\n",
    "    driver.execute_script(\"window.open('{}');\".format(topic_url))\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')))\n",
    "\n",
    "    main_content_element = driver.find_element(By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')\n",
    "    main_content = main_content_element.text if main_content_element else \"Content not found\"\n",
    "\n",
    "    likes_element = driver.find_element(By.CSS_SELECTOR, 'label._1yxPOd27pAzF9olhItRDej')\n",
    "    likes = likes_element.text if likes_element else \"Likes not found\"\n",
    "\n",
    "    dislikes_element = driver.find_element(By.CSS_SELECTOR, 'label._2iRKJuMIV77zdwLRreUgLK')\n",
    "    dislikes = dislikes_element.text if dislikes_element else \"Dislikes not found\"\n",
    "\n",
    "    replies = scrape_replies(driver, topic_url)\n",
    "\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "    data.append([title, username, main_content, likes, dislikes, topic_url, replies])\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "csv_file_name = \"騙徒手法層出不窮.csv\"\n",
    "\n",
    "with open(csv_file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Username\", \"Main Content\", \"Likes\", \"Dislikes\", \"URL\", \"All Replies\"])\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Data successfully written to {csv_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fefa2df-3aa6-4a18-b050-9fbda53ec852",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#電郵騙案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a2ccc37-4c93-495a-b4ed-35451295aa4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to 電郵騙案.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "def scrape_replies(driver, topic_url):\n",
    "    driver.get(topic_url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    all_replies = []\n",
    "\n",
    "    while True:\n",
    "        reply_elements = driver.find_elements(By.CSS_SELECTOR, 'div._36ZEkSvpdj_igmog0nluzh')\n",
    "        for reply_element in reply_elements:\n",
    "            reply_text = reply_element.text.replace(\"\\n\", \" \").strip()\n",
    "            all_replies.append(reply_text)\n",
    "\n",
    "        next_page_buttons = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/page/']\")\n",
    "        next_page_found = False\n",
    "        for button in next_page_buttons:\n",
    "            if button.text == \"下一頁\":\n",
    "                next_url = button.get_attribute('href')\n",
    "                driver.get(next_url)\n",
    "                time.sleep(5)  # Wait for the next page to load\n",
    "                next_page_found = True\n",
    "                break\n",
    "\n",
    "        if not next_page_found:\n",
    "            break\n",
    "\n",
    "    return \" | \".join(all_replies)\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chromedriver_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\Miki\\\\5508\\\\Project\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "service = Service(executable_path=chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "url = 'https://lihkg.com/search?q=%E9%9B%BB%E9%83%B5%E9%A8%99%E6%A1%88&sort=desc_create_time&type=thread'\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "data = []\n",
    "topics = driver.find_elements(By.CLASS_NAME, 'wQ4Ran7ySbKd8PdMeHZZR')\n",
    "\n",
    "for topic in topics:\n",
    "    title = topic.find_element(By.CSS_SELECTOR, 'span._20jopXBFHNQ9FUbcGHLcHH').text.strip()\n",
    "    username = topic.find_element(By.CSS_SELECTOR, 'span.CxY4XDSSItTeLVg0cKCN0').text.strip()\n",
    "    topic_url_element = topic.find_element(By.CSS_SELECTOR, 'a._2A_7bGY9QAXcGu1neEYDJB')\n",
    "    topic_url = topic_url_element.get_attribute('href')\n",
    "\n",
    "    driver.execute_script(\"window.open('{}');\".format(topic_url))\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')))\n",
    "\n",
    "    main_content_element = driver.find_element(By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')\n",
    "    main_content = main_content_element.text if main_content_element else \"Content not found\"\n",
    "\n",
    "    likes_element = driver.find_element(By.CSS_SELECTOR, 'label._1yxPOd27pAzF9olhItRDej')\n",
    "    likes = likes_element.text if likes_element else \"Likes not found\"\n",
    "\n",
    "    dislikes_element = driver.find_element(By.CSS_SELECTOR, 'label._2iRKJuMIV77zdwLRreUgLK')\n",
    "    dislikes = dislikes_element.text if dislikes_element else \"Dislikes not found\"\n",
    "\n",
    "    replies = scrape_replies(driver, topic_url)\n",
    "\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "    data.append([title, username, main_content, likes, dislikes, topic_url, replies])\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "csv_file_name = \"電郵騙案.csv\"\n",
    "\n",
    "with open(csv_file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Username\", \"Main Content\", \"Likes\", \"Dislikes\", \"URL\", \"All Replies\"])\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Data successfully written to {csv_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd86959d-a8ab-45af-93da-913c5c2f4d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#網上情緣騙案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b787383e-693a-4ea7-95cc-7781893e49cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to 網上情緣騙案.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "def scrape_replies(driver, topic_url):\n",
    "    driver.get(topic_url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    all_replies = []\n",
    "\n",
    "    while True:\n",
    "        reply_elements = driver.find_elements(By.CSS_SELECTOR, 'div._36ZEkSvpdj_igmog0nluzh')\n",
    "        for reply_element in reply_elements:\n",
    "            reply_text = reply_element.text.replace(\"\\n\", \" \").strip()\n",
    "            all_replies.append(reply_text)\n",
    "\n",
    "        next_page_buttons = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/page/']\")\n",
    "        next_page_found = False\n",
    "        for button in next_page_buttons:\n",
    "            if button.text == \"下一頁\":\n",
    "                next_url = button.get_attribute('href')\n",
    "                driver.get(next_url)\n",
    "                time.sleep(5)  # Wait for the next page to load\n",
    "                next_page_found = True\n",
    "                break\n",
    "\n",
    "        if not next_page_found:\n",
    "            break\n",
    "\n",
    "    return \" | \".join(all_replies)\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chromedriver_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\Miki\\\\5508\\\\Project\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "service = Service(executable_path=chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "url = 'https://lihkg.com/search?q=%E7%B6%B2%E4%B8%8A%E6%83%85%E7%B7%A3%E9%A8%99%E6%A1%88&sort=desc_create_time&type=thread'\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "data = []\n",
    "topics = driver.find_elements(By.CLASS_NAME, 'wQ4Ran7ySbKd8PdMeHZZR')\n",
    "\n",
    "for topic in topics:\n",
    "    title = topic.find_element(By.CSS_SELECTOR, 'span._20jopXBFHNQ9FUbcGHLcHH').text.strip()\n",
    "    username = topic.find_element(By.CSS_SELECTOR, 'span.CxY4XDSSItTeLVg0cKCN0').text.strip()\n",
    "    topic_url_element = topic.find_element(By.CSS_SELECTOR, 'a._2A_7bGY9QAXcGu1neEYDJB')\n",
    "    topic_url = topic_url_element.get_attribute('href')\n",
    "\n",
    "    driver.execute_script(\"window.open('{}');\".format(topic_url))\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')))\n",
    "\n",
    "    main_content_element = driver.find_element(By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')\n",
    "    main_content = main_content_element.text if main_content_element else \"Content not found\"\n",
    "\n",
    "    likes_element = driver.find_element(By.CSS_SELECTOR, 'label._1yxPOd27pAzF9olhItRDej')\n",
    "    likes = likes_element.text if likes_element else \"Likes not found\"\n",
    "\n",
    "    dislikes_element = driver.find_element(By.CSS_SELECTOR, 'label._2iRKJuMIV77zdwLRreUgLK')\n",
    "    dislikes = dislikes_element.text if dislikes_element else \"Dislikes not found\"\n",
    "\n",
    "    replies = scrape_replies(driver, topic_url)\n",
    "\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "    data.append([title, username, main_content, likes, dislikes, topic_url, replies])\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "csv_file_name = \"網上情緣騙案.csv\"\n",
    "\n",
    "with open(csv_file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Username\", \"Main Content\", \"Likes\", \"Dislikes\", \"URL\", \"All Replies\"])\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Data successfully written to {csv_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d00da96-f2da-451c-9c81-cddbc1b9467a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#交友app 騙案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9707358f-49ef-4bea-96ff-675f265033b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to 交友app騙案.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "def scrape_replies(driver, topic_url):\n",
    "    driver.get(topic_url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    all_replies = []\n",
    "\n",
    "    while True:\n",
    "        reply_elements = driver.find_elements(By.CSS_SELECTOR, 'div._36ZEkSvpdj_igmog0nluzh')\n",
    "        for reply_element in reply_elements:\n",
    "            reply_text = reply_element.text.replace(\"\\n\", \" \").strip()\n",
    "            all_replies.append(reply_text)\n",
    "\n",
    "        next_page_buttons = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/page/']\")\n",
    "        next_page_found = False\n",
    "        for button in next_page_buttons:\n",
    "            if button.text == \"下一頁\":\n",
    "                next_url = button.get_attribute('href')\n",
    "                driver.get(next_url)\n",
    "                time.sleep(5)  # Wait for the next page to load\n",
    "                next_page_found = True\n",
    "                break\n",
    "\n",
    "        if not next_page_found:\n",
    "            break\n",
    "\n",
    "    return \" | \".join(all_replies)\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chromedriver_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\Miki\\\\5508\\\\Project\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "service = Service(executable_path=chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "url = 'https://lihkg.com/search?q=%E4%BA%A4%E5%8F%8Bapp%E9%A8%99%E6%A1%88%20&sort=desc_create_time&type=thread'\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "data = []\n",
    "topics = driver.find_elements(By.CLASS_NAME, 'wQ4Ran7ySbKd8PdMeHZZR')\n",
    "\n",
    "for topic in topics:\n",
    "    title = topic.find_element(By.CSS_SELECTOR, 'span._20jopXBFHNQ9FUbcGHLcHH').text.strip()\n",
    "    username = topic.find_element(By.CSS_SELECTOR, 'span.CxY4XDSSItTeLVg0cKCN0').text.strip()\n",
    "    topic_url_element = topic.find_element(By.CSS_SELECTOR, 'a._2A_7bGY9QAXcGu1neEYDJB')\n",
    "    topic_url = topic_url_element.get_attribute('href')\n",
    "\n",
    "    driver.execute_script(\"window.open('{}');\".format(topic_url))\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')))\n",
    "\n",
    "    main_content_element = driver.find_element(By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')\n",
    "    main_content = main_content_element.text if main_content_element else \"Content not found\"\n",
    "\n",
    "    likes_element = driver.find_element(By.CSS_SELECTOR, 'label._1yxPOd27pAzF9olhItRDej')\n",
    "    likes = likes_element.text if likes_element else \"Likes not found\"\n",
    "\n",
    "    dislikes_element = driver.find_element(By.CSS_SELECTOR, 'label._2iRKJuMIV77zdwLRreUgLK')\n",
    "    dislikes = dislikes_element.text if dislikes_element else \"Dislikes not found\"\n",
    "\n",
    "    replies = scrape_replies(driver, topic_url)\n",
    "\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "    data.append([title, username, main_content, likes, dislikes, topic_url, replies])\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "csv_file_name = \"交友app騙案.csv\"\n",
    "\n",
    "with open(csv_file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Username\", \"Main Content\", \"Likes\", \"Dislikes\", \"URL\", \"All Replies\"])\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Data successfully written to {csv_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29ff449f-2dae-4841-96e6-e2368eb95336",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#facebook騙案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6461ed87-b0da-41e1-818a-55f5d525fe84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to facebook騙案.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "def scrape_replies(driver, topic_url):\n",
    "    driver.get(topic_url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    all_replies = []\n",
    "\n",
    "    while True:\n",
    "        reply_elements = driver.find_elements(By.CSS_SELECTOR, 'div._36ZEkSvpdj_igmog0nluzh')\n",
    "        for reply_element in reply_elements:\n",
    "            reply_text = reply_element.text.replace(\"\\n\", \" \").strip()\n",
    "            all_replies.append(reply_text)\n",
    "\n",
    "        next_page_buttons = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/page/']\")\n",
    "        next_page_found = False\n",
    "        for button in next_page_buttons:\n",
    "            if button.text == \"下一頁\":\n",
    "                next_url = button.get_attribute('href')\n",
    "                driver.get(next_url)\n",
    "                time.sleep(5)  # Wait for the next page to load\n",
    "                next_page_found = True\n",
    "                break\n",
    "\n",
    "        if not next_page_found:\n",
    "            break\n",
    "\n",
    "    return \" | \".join(all_replies)\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chromedriver_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\Miki\\\\5508\\\\Project\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "service = Service(executable_path=chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "url = 'https://lihkg.com/search?q=facebook%E9%A8%99%E6%A1%88&sort=desc_create_time&type=thread'\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "data = []\n",
    "topics = driver.find_elements(By.CLASS_NAME, 'wQ4Ran7ySbKd8PdMeHZZR')\n",
    "\n",
    "for topic in topics:\n",
    "    title = topic.find_element(By.CSS_SELECTOR, 'span._20jopXBFHNQ9FUbcGHLcHH').text.strip()\n",
    "    username = topic.find_element(By.CSS_SELECTOR, 'span.CxY4XDSSItTeLVg0cKCN0').text.strip()\n",
    "    topic_url_element = topic.find_element(By.CSS_SELECTOR, 'a._2A_7bGY9QAXcGu1neEYDJB')\n",
    "    topic_url = topic_url_element.get_attribute('href')\n",
    "\n",
    "    driver.execute_script(\"window.open('{}');\".format(topic_url))\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')))\n",
    "\n",
    "    main_content_element = driver.find_element(By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')\n",
    "    main_content = main_content_element.text if main_content_element else \"Content not found\"\n",
    "\n",
    "    likes_element = driver.find_element(By.CSS_SELECTOR, 'label._1yxPOd27pAzF9olhItRDej')\n",
    "    likes = likes_element.text if likes_element else \"Likes not found\"\n",
    "\n",
    "    dislikes_element = driver.find_element(By.CSS_SELECTOR, 'label._2iRKJuMIV77zdwLRreUgLK')\n",
    "    dislikes = dislikes_element.text if dislikes_element else \"Dislikes not found\"\n",
    "\n",
    "    replies = scrape_replies(driver, topic_url)\n",
    "\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "    data.append([title, username, main_content, likes, dislikes, topic_url, replies])\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "csv_file_name = \"facebook騙案.csv\"\n",
    "\n",
    "with open(csv_file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Username\", \"Main Content\", \"Likes\", \"Dislikes\", \"URL\", \"All Replies\"])\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Data successfully written to {csv_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee74e0db-6e32-41ed-aec2-60911ffca1e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ig騙案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8798967-0951-44da-935b-d11e68af6b59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to ig騙案.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "def scrape_replies(driver, topic_url):\n",
    "    driver.get(topic_url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    all_replies = []\n",
    "\n",
    "    while True:\n",
    "        reply_elements = driver.find_elements(By.CSS_SELECTOR, 'div._36ZEkSvpdj_igmog0nluzh')\n",
    "        for reply_element in reply_elements:\n",
    "            reply_text = reply_element.text.replace(\"\\n\", \" \").strip()\n",
    "            all_replies.append(reply_text)\n",
    "\n",
    "        next_page_buttons = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/page/']\")\n",
    "        next_page_found = False\n",
    "        for button in next_page_buttons:\n",
    "            if button.text == \"下一頁\":\n",
    "                next_url = button.get_attribute('href')\n",
    "                driver.get(next_url)\n",
    "                time.sleep(5)  # Wait for the next page to load\n",
    "                next_page_found = True\n",
    "                break\n",
    "\n",
    "        if not next_page_found:\n",
    "            break\n",
    "\n",
    "    return \" | \".join(all_replies)\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chromedriver_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\Miki\\\\5508\\\\Project\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "service = Service(executable_path=chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "url = 'https://lihkg.com/search?q=ig%E9%A8%99%E6%A1%88&sort=desc_create_time&type=thread'\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "data = []\n",
    "topics = driver.find_elements(By.CLASS_NAME, 'wQ4Ran7ySbKd8PdMeHZZR')\n",
    "\n",
    "for topic in topics:\n",
    "    title = topic.find_element(By.CSS_SELECTOR, 'span._20jopXBFHNQ9FUbcGHLcHH').text.strip()\n",
    "    username = topic.find_element(By.CSS_SELECTOR, 'span.CxY4XDSSItTeLVg0cKCN0').text.strip()\n",
    "    topic_url_element = topic.find_element(By.CSS_SELECTOR, 'a._2A_7bGY9QAXcGu1neEYDJB')\n",
    "    topic_url = topic_url_element.get_attribute('href')\n",
    "\n",
    "    driver.execute_script(\"window.open('{}');\".format(topic_url))\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')))\n",
    "\n",
    "    main_content_element = driver.find_element(By.CSS_SELECTOR, 'div._2cNsJna0_hV8tdMj3X6_gJ')\n",
    "    main_content = main_content_element.text if main_content_element else \"Content not found\"\n",
    "\n",
    "    likes_element = driver.find_element(By.CSS_SELECTOR, 'label._1yxPOd27pAzF9olhItRDej')\n",
    "    likes = likes_element.text if likes_element else \"Likes not found\"\n",
    "\n",
    "    dislikes_element = driver.find_element(By.CSS_SELECTOR, 'label._2iRKJuMIV77zdwLRreUgLK')\n",
    "    dislikes = dislikes_element.text if dislikes_element else \"Dislikes not found\"\n",
    "\n",
    "    replies = scrape_replies(driver, topic_url)\n",
    "\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "    data.append([title, username, main_content, likes, dislikes, topic_url, replies])\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "csv_file_name = \"ig騙案.csv\"\n",
    "\n",
    "with open(csv_file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Username\", \"Main Content\", \"Likes\", \"Dislikes\", \"URL\", \"All Replies\"])\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Data successfully written to {csv_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9f2cb9-0513-4cd3-9ee2-c5ff91c60dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
